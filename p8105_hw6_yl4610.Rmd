---
title: "p8105_hw6_yl4610"
output: github_document
author: "Yuxin Liu"
date: "2022-11-21"
---

```{r setup, message=FALSE}
library(tidyverse)
library(modelr)
library(skimr)
```

# Question 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

# Question 2
```{r, message=FALSE}
homicide_raw = 
  read_csv( "./data/homicide_data.csv") %>% 
    mutate (
    city_state = str_c(city, ", ", state),
    result = ifelse(disposition != "Closed by arrest", "unsolved", "solved")) %>% 
    filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) %>% 
    filter(victim_race %in% c("White", "Black")) %>% 
    filter(!(victim_age %in% c("Unknown"))) %>% 
    mutate (victim_age = as.numeric(victim_age))

homicide_raw 
```
I used mutate to create a city_state variable and a binary variable indicating whether the homicide is solved. I used filter to omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO; Tulsa, AL. Also, I used filter to limit victim_race as White or Black and delete unknown age. Lastly, I used mutate to change victim_age to numeric format.

```{r}
Baltimore_reg = 
 homicide_raw %>% 
  filter(city_state == "Baltimore, MD") %>%
  mutate (y_var = ifelse(result == "solved",1,0)) %>% 
    glm(y_var ~ victim_age + victim_sex + victim_race, data =., family = 'binomial'(link='logit')) %>% 
    broom::tidy () %>% 
    mutate(odds_ratio = exp(estimate),
           lower_bound = exp(estimate - 1.96 * std.error),
           upper_bound = exp(estimate + 1.96 * std.error)) %>% 
    select(term, estimate, odds_ratio, lower_bound,upper_bound ) %>% 
    filter(term == "victim_sexMale") 

Baltimore_reg
```
For the city of Baltimore, MD, I used the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object.
The estimate is -0.85. The adjusted odds ratio is 0.43 and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed is (0.32, 0.56).


```{r}
homicide_all_cities = 
  homicide_raw %>% 
  mutate (y_var = ifelse(result == "solved",1,0)) %>%
  nest(data = -city_state) %>% 
  mutate(
    glm_all_cities = map(data, ~glm(y_var ~ victim_age + victim_sex + victim_race, data = ., family = 'binomial'(link='logit'))),
    final_results = map(glm_all_cities, broom::tidy)) %>% 
  unnest(final_results) %>% 
  mutate(
    odds_ratio = exp(estimate),
    lower_bound = exp(estimate - 1.96 * std.error),
    upper_bound = exp(estimate + 1.96 * std.error)) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, odds_ratio, lower_bound,upper_bound) 

homicide_all_cities
```
I run glm for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. I did this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest to create a dataframe with estimated ORs and CIs for each city.

```{r}
homicide_plot = 
  homicide_all_cities %>% 
    mutate(city_state = fct_reorder(city_state, odds_ratio)) %>% 
    ggplot(aes(x = city_state, y = odds_ratio, color = city_state)) + 
    geom_point() + 
    geom_errorbar(aes(ymin = lower_bound, ymax = upper_bound)) + 
    theme(axis.text.x = element_text(angle=90, hjust = 1)) + 
    labs(x = "City States",
         y = "Estimated Odds Ratios",
         title = "estimated ORs and CIs for each city") +
    theme(legend.position = "none") 

homicide_plot
```

I created a plot that shows the estimated ORs and CIs for each city. Then I organized cities according to estimated OR.
This scatter plot shows that New York, NY has the lowest estimated odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed, while Albuquerque, NM has the highest estimated odds ratio. Also, the 95% CI for Albuquerque, NM is the widest when compared to other city states.

# Question 3 
```{r, message = FALSE}
birthweight_raw = 
  read_csv("./data/birthweight.csv") %>% 
    mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))
```

```{r}
skimr::skim(birthweight_raw) 
```
According to the output of skimr::skim, there is no missing data.
I Loaded and cleaned the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
model = lm(bwt ~ ., data = birthweight_raw) 

model%>%
  broom::tidy() %>% 
  knitr::kable(digits = 4)

regression_model = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_raw) 

regression_model %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4)

regression_model
```
I proposed a regression model for birthweight (named as regression_model). Since it is a linear regression model, I used "Backward Elimination" strategy to build the model.First, I built a maximum model including all the predictors, then I deleted one predictor each time by determining whether the least significant variable currently in the model can be removed because of its high p value (>0.05). Finally, all the predictors in the model have p-value less than 0.05. mrace3 has p-value greater than 0.05, but other categories of this predictor have p-values less than 0.05, so I kept it. I did not include the process of deleting one predictor each time because it is too long, so I only kept the final model.

```{r}
residual_plot =
  birthweight_raw %>% 
  modelr::add_predictions(regression_model) %>% 
  modelr::add_residuals(regression_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5, cex=0.5) +
  labs(
    title = "residuals against fitted values",
    x = "fitted values",
    y = "residuals") +
  theme(axis.text.x = element_text(angle=90, hjust = 1)) +
  geom_line(aes(y = 0), color = "red") 

residual_plot
```

I created a plot of model residuals against fitted values – use add_predictions and add_residuals.

```{r}
compare_model1 = lm(bwt ~ blength + gaweeks, data = birthweight_raw) 

compare_model1 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4)

compare_model2 = lm(bwt ~  bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight_raw) 

compare_model2 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4)
```
I compared the model to two others:
One using length at birth and gestational age as predictors (main effects only). One using head circumference, length, sex, and all interactions (including the three-way interaction) between these.

```{r}
cv_df = crossv_mc(birthweight_raw, 100)

cv = 
  cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    compare_model1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = birthweight_raw)),
    compare_model2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = birthweight_raw)),
    regression_model = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_raw))) %>% 
  mutate(
    rmse_model1 = map2_dbl(.x = compare_model1, .y = test, ~rmse(.x,.y)),
    rmse_model2 = map2_dbl(.x = compare_model2, .y = test, ~rmse(.x,.y)),
    rmse_regression_model = map2_dbl(regression_model, .y = test, ~rmse(model = .x, .y))) %>% 
  select(rmse_model1, rmse_model2, rmse_regression_model)

cv
```
I made the comparison in terms of the cross-validated prediction error, used crossv_mc, and used functions in purrr as appropriate.

```{r}
comparison_plot =
  cv %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "rmse of 3 different models",
    x = "model",
    y = "rmse") 

comparison_plot
```
My model has lower average rmse when compared to two other models. 
